{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c28963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3459a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARLSTem',\n",
       " 'ARLSTem2',\n",
       " 'AbstractLazySequence',\n",
       " 'AffixTagger',\n",
       " 'AlignedSent',\n",
       " 'Alignment',\n",
       " 'AnnotationTask',\n",
       " 'ApplicationExpression',\n",
       " 'Assignment',\n",
       " 'BigramAssocMeasures',\n",
       " 'BigramCollocationFinder',\n",
       " 'BigramTagger',\n",
       " 'BinaryMaxentFeatureEncoding',\n",
       " 'BlanklineTokenizer',\n",
       " 'BllipParser',\n",
       " 'BottomUpChartParser',\n",
       " 'BottomUpLeftCornerChartParser',\n",
       " 'BottomUpProbabilisticChartParser',\n",
       " 'Boxer',\n",
       " 'BrillTagger',\n",
       " 'BrillTaggerTrainer',\n",
       " 'CFG',\n",
       " 'CRFTagger',\n",
       " 'CfgReadingCommand',\n",
       " 'ChartParser',\n",
       " 'ChunkParserI',\n",
       " 'ChunkScore',\n",
       " 'Cistem',\n",
       " 'ClassifierBasedPOSTagger',\n",
       " 'ClassifierBasedTagger',\n",
       " 'ClassifierI',\n",
       " 'ConcordanceIndex',\n",
       " 'ConditionalExponentialClassifier',\n",
       " 'ConditionalFreqDist',\n",
       " 'ConditionalProbDist',\n",
       " 'ConditionalProbDistI',\n",
       " 'ConfusionMatrix',\n",
       " 'ContextIndex',\n",
       " 'ContextTagger',\n",
       " 'ContingencyMeasures',\n",
       " 'CoreNLPDependencyParser',\n",
       " 'CoreNLPParser',\n",
       " 'Counter',\n",
       " 'CrossValidationProbDist',\n",
       " 'DRS',\n",
       " 'DecisionTreeClassifier',\n",
       " 'DefaultTagger',\n",
       " 'DependencyEvaluator',\n",
       " 'DependencyGrammar',\n",
       " 'DependencyGraph',\n",
       " 'DependencyProduction',\n",
       " 'DictionaryConditionalProbDist',\n",
       " 'DictionaryProbDist',\n",
       " 'DiscourseTester',\n",
       " 'DrtExpression',\n",
       " 'DrtGlueReadingCommand',\n",
       " 'ELEProbDist',\n",
       " 'EarleyChartParser',\n",
       " 'Expression',\n",
       " 'FStructure',\n",
       " 'FeatDict',\n",
       " 'FeatList',\n",
       " 'FeatStruct',\n",
       " 'FeatStructReader',\n",
       " 'Feature',\n",
       " 'FeatureBottomUpChartParser',\n",
       " 'FeatureBottomUpLeftCornerChartParser',\n",
       " 'FeatureChartParser',\n",
       " 'FeatureEarleyChartParser',\n",
       " 'FeatureIncrementalBottomUpChartParser',\n",
       " 'FeatureIncrementalBottomUpLeftCornerChartParser',\n",
       " 'FeatureIncrementalChartParser',\n",
       " 'FeatureIncrementalTopDownChartParser',\n",
       " 'FeatureTopDownChartParser',\n",
       " 'FreqDist',\n",
       " 'HTTPPasswordMgrWithDefaultRealm',\n",
       " 'HeldoutProbDist',\n",
       " 'HiddenMarkovModelTagger',\n",
       " 'HiddenMarkovModelTrainer',\n",
       " 'HunposTagger',\n",
       " 'IBMModel',\n",
       " 'IBMModel1',\n",
       " 'IBMModel2',\n",
       " 'IBMModel3',\n",
       " 'IBMModel4',\n",
       " 'IBMModel5',\n",
       " 'ISRIStemmer',\n",
       " 'ImmutableMultiParentedTree',\n",
       " 'ImmutableParentedTree',\n",
       " 'ImmutableProbabilisticMixIn',\n",
       " 'ImmutableProbabilisticTree',\n",
       " 'ImmutableTree',\n",
       " 'IncrementalBottomUpChartParser',\n",
       " 'IncrementalBottomUpLeftCornerChartParser',\n",
       " 'IncrementalChartParser',\n",
       " 'IncrementalLeftCornerChartParser',\n",
       " 'IncrementalTopDownChartParser',\n",
       " 'Index',\n",
       " 'InsideChartParser',\n",
       " 'JSONTaggedDecoder',\n",
       " 'JSONTaggedEncoder',\n",
       " 'KneserNeyProbDist',\n",
       " 'LancasterStemmer',\n",
       " 'LaplaceProbDist',\n",
       " 'LazyConcatenation',\n",
       " 'LazyEnumerate',\n",
       " 'LazyIteratorList',\n",
       " 'LazyMap',\n",
       " 'LazySubsequence',\n",
       " 'LazyZip',\n",
       " 'LeftCornerChartParser',\n",
       " 'LegalitySyllableTokenizer',\n",
       " 'LidstoneProbDist',\n",
       " 'LineTokenizer',\n",
       " 'LogicalExpressionException',\n",
       " 'LongestChartParser',\n",
       " 'MLEProbDist',\n",
       " 'MWETokenizer',\n",
       " 'Mace',\n",
       " 'MaceCommand',\n",
       " 'MaltParser',\n",
       " 'MaxentClassifier',\n",
       " 'Model',\n",
       " 'MultiClassifierI',\n",
       " 'MultiParentedTree',\n",
       " 'MutableProbDist',\n",
       " 'NLTKWordTokenizer',\n",
       " 'NaiveBayesClassifier',\n",
       " 'NaiveBayesDependencyScorer',\n",
       " 'NgramAssocMeasures',\n",
       " 'NgramTagger',\n",
       " 'NonprojectiveDependencyParser',\n",
       " 'Nonterminal',\n",
       " 'OrderedDict',\n",
       " 'PCFG',\n",
       " 'Paice',\n",
       " 'ParallelProverBuilder',\n",
       " 'ParallelProverBuilderCommand',\n",
       " 'ParentedTree',\n",
       " 'ParserI',\n",
       " 'PerceptronTagger',\n",
       " 'PhraseTable',\n",
       " 'PorterStemmer',\n",
       " 'PositiveNaiveBayesClassifier',\n",
       " 'ProbDistI',\n",
       " 'ProbabilisticDependencyGrammar',\n",
       " 'ProbabilisticMixIn',\n",
       " 'ProbabilisticNonprojectiveParser',\n",
       " 'ProbabilisticProduction',\n",
       " 'ProbabilisticProjectiveDependencyParser',\n",
       " 'ProbabilisticTree',\n",
       " 'Production',\n",
       " 'ProjectiveDependencyParser',\n",
       " 'Prover9',\n",
       " 'Prover9Command',\n",
       " 'ProxyBasicAuthHandler',\n",
       " 'ProxyDigestAuthHandler',\n",
       " 'ProxyHandler',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'QuadgramAssocMeasures',\n",
       " 'QuadgramCollocationFinder',\n",
       " 'RSLPStemmer',\n",
       " 'RTEFeatureExtractor',\n",
       " 'RUS_PICKLE',\n",
       " 'RandomChartParser',\n",
       " 'RangeFeature',\n",
       " 'ReadingCommand',\n",
       " 'RecursiveDescentParser',\n",
       " 'RegexpChunkParser',\n",
       " 'RegexpParser',\n",
       " 'RegexpStemmer',\n",
       " 'RegexpTagger',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'ResolutionProver',\n",
       " 'ResolutionProverCommand',\n",
       " 'SExprTokenizer',\n",
       " 'SLASH',\n",
       " 'Senna',\n",
       " 'SennaChunkTagger',\n",
       " 'SennaNERTagger',\n",
       " 'SennaTagger',\n",
       " 'SequentialBackoffTagger',\n",
       " 'ShiftReduceParser',\n",
       " 'SimpleGoodTuringProbDist',\n",
       " 'SklearnClassifier',\n",
       " 'SlashFeature',\n",
       " 'SnowballStemmer',\n",
       " 'SpaceTokenizer',\n",
       " 'StackDecoder',\n",
       " 'StanfordNERTagger',\n",
       " 'StanfordPOSTagger',\n",
       " 'StanfordSegmenter',\n",
       " 'StanfordTagger',\n",
       " 'StemmerI',\n",
       " 'SteppingChartParser',\n",
       " 'SteppingRecursiveDescentParser',\n",
       " 'SteppingShiftReduceParser',\n",
       " 'SyllableTokenizer',\n",
       " 'TYPE',\n",
       " 'TabTokenizer',\n",
       " 'TableauProver',\n",
       " 'TableauProverCommand',\n",
       " 'TaggerI',\n",
       " 'TestGrammar',\n",
       " 'Text',\n",
       " 'TextCat',\n",
       " 'TextCollection',\n",
       " 'TextTilingTokenizer',\n",
       " 'TnT',\n",
       " 'TokenSearcher',\n",
       " 'ToktokTokenizer',\n",
       " 'TopDownChartParser',\n",
       " 'TransitionParser',\n",
       " 'Tree',\n",
       " 'TreebankWordTokenizer',\n",
       " 'Trie',\n",
       " 'TrigramAssocMeasures',\n",
       " 'TrigramCollocationFinder',\n",
       " 'TrigramTagger',\n",
       " 'TweetTokenizer',\n",
       " 'TypedMaxentFeatureEncoding',\n",
       " 'Undefined',\n",
       " 'UniformProbDist',\n",
       " 'UnigramTagger',\n",
       " 'UnsortedChartParser',\n",
       " 'Valuation',\n",
       " 'Variable',\n",
       " 'ViterbiParser',\n",
       " 'WekaClassifier',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WittenBellProbDist',\n",
       " 'WordNetLemmatizer',\n",
       " 'WordPunctTokenizer',\n",
       " '__author__',\n",
       " '__author_email__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__classifiers__',\n",
       " '__copyright__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__keywords__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__longdescr__',\n",
       " '__maintainer__',\n",
       " '__maintainer_email__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__url__',\n",
       " '__version__',\n",
       " 'accuracy',\n",
       " 'acyclic_branches_depth_first',\n",
       " 'acyclic_breadth_first',\n",
       " 'acyclic_depth_first',\n",
       " 'acyclic_dic2tree',\n",
       " 'add_logs',\n",
       " 'agreement',\n",
       " 'align',\n",
       " 'alignment_error_rate',\n",
       " 'aline',\n",
       " 'api',\n",
       " 'app',\n",
       " 'apply_features',\n",
       " 'approxrand',\n",
       " 'arity',\n",
       " 'arlstem',\n",
       " 'arlstem2',\n",
       " 'association',\n",
       " 'bigrams',\n",
       " 'binary_distance',\n",
       " 'binary_search_file',\n",
       " 'binding_ops',\n",
       " 'bisect',\n",
       " 'blankline_tokenize',\n",
       " 'bleu',\n",
       " 'bleu_score',\n",
       " 'bllip',\n",
       " 'boolean_ops',\n",
       " 'boxer',\n",
       " 'bracket_parse',\n",
       " 'breadth_first',\n",
       " 'brill',\n",
       " 'brill_trainer',\n",
       " 'build_opener',\n",
       " 'call_megam',\n",
       " 'casual',\n",
       " 'casual_tokenize',\n",
       " 'ccg',\n",
       " 'chain',\n",
       " 'chart',\n",
       " 'chat',\n",
       " 'choose',\n",
       " 'chrf',\n",
       " 'chrf_score',\n",
       " 'chunk',\n",
       " 'cistem',\n",
       " 'classify',\n",
       " 'clause',\n",
       " 'clean_html',\n",
       " 'clean_url',\n",
       " 'cluster',\n",
       " 'collections',\n",
       " 'collocations',\n",
       " 'combinations',\n",
       " 'compat',\n",
       " 'config_java',\n",
       " 'config_megam',\n",
       " 'config_weka',\n",
       " 'conflicts',\n",
       " 'confusionmatrix',\n",
       " 'conllstr2tree',\n",
       " 'conlltags2tree',\n",
       " 'corenlp',\n",
       " 'corpus',\n",
       " 'crf',\n",
       " 'custom_distance',\n",
       " 'data',\n",
       " 'decisiontree',\n",
       " 'decorator',\n",
       " 'decorators',\n",
       " 'defaultdict',\n",
       " 'demo',\n",
       " 'dependencygraph',\n",
       " 'deprecated',\n",
       " 'deque',\n",
       " 'destructive',\n",
       " 'discourse',\n",
       " 'distance',\n",
       " 'download',\n",
       " 'download_gui',\n",
       " 'download_shell',\n",
       " 'downloader',\n",
       " 'draw',\n",
       " 'drt',\n",
       " 'earleychart',\n",
       " 'edge_closure',\n",
       " 'edges2dot',\n",
       " 'edit_distance',\n",
       " 'edit_distance_align',\n",
       " 'elementtree_indent',\n",
       " 'entropy',\n",
       " 'equality_preds',\n",
       " 'evaluate',\n",
       " 'evaluate_sents',\n",
       " 'everygrams',\n",
       " 'extract',\n",
       " 'extract_rels',\n",
       " 'extract_test_sentences',\n",
       " 'f_measure',\n",
       " 'featstruct',\n",
       " 'featurechart',\n",
       " 'filestring',\n",
       " 'find',\n",
       " 'flatten',\n",
       " 'fractional_presence',\n",
       " 'gale_church',\n",
       " 'gdfa',\n",
       " 'getproxies',\n",
       " 'ghd',\n",
       " 'gleu',\n",
       " 'gleu_score',\n",
       " 'glue',\n",
       " 'grammar',\n",
       " 'grow_diag_final_and',\n",
       " 'guess_encoding',\n",
       " 'help',\n",
       " 'hmm',\n",
       " 'hunpos',\n",
       " 'ibm1',\n",
       " 'ibm2',\n",
       " 'ibm3',\n",
       " 'ibm4',\n",
       " 'ibm5',\n",
       " 'ibm_model',\n",
       " 'ieerstr2tree',\n",
       " 'in_idle',\n",
       " 'induce_pcfg',\n",
       " 'inference',\n",
       " 'infile',\n",
       " 'inspect',\n",
       " 'install_opener',\n",
       " 'internals',\n",
       " 'interpret_sents',\n",
       " 'interval_distance',\n",
       " 'invert_dict',\n",
       " 'invert_graph',\n",
       " 'is_rel',\n",
       " 'islice',\n",
       " 'isri',\n",
       " 'jaccard_distance',\n",
       " 'json_tags',\n",
       " 'jsontags',\n",
       " 'lancaster',\n",
       " 'lazyimport',\n",
       " 'legality_principle',\n",
       " 'lfg',\n",
       " 'line_tokenize',\n",
       " 'linearlogic',\n",
       " 'lm',\n",
       " 'load',\n",
       " 'load_parser',\n",
       " 'locale',\n",
       " 'log_likelihood',\n",
       " 'logic',\n",
       " 'mace',\n",
       " 'malt',\n",
       " 'map_tag',\n",
       " 'mapping',\n",
       " 'masi_distance',\n",
       " 'maxent',\n",
       " 'megam',\n",
       " 'memoize',\n",
       " 'meteor',\n",
       " 'meteor_score',\n",
       " 'metrics',\n",
       " 'misc',\n",
       " 'mwe',\n",
       " 'naivebayes',\n",
       " 'ne_chunk',\n",
       " 'ne_chunk_sents',\n",
       " 'ngrams',\n",
       " 'nist',\n",
       " 'nist_score',\n",
       " 'nonprojectivedependencyparser',\n",
       " 'nonterminals',\n",
       " 'numpy',\n",
       " 'os',\n",
       " 'pad_sequence',\n",
       " 'paice',\n",
       " 'pairwise',\n",
       " 'parallelize_preprocess',\n",
       " 'parse',\n",
       " 'parse_sents',\n",
       " 'pchart',\n",
       " 'perceptron',\n",
       " 'phrase_based',\n",
       " 'pk',\n",
       " 'porter',\n",
       " 'pos_tag',\n",
       " 'pos_tag_sents',\n",
       " 'positivenaivebayes',\n",
       " 'pprint',\n",
       " 'pr',\n",
       " 'precision',\n",
       " 'presence',\n",
       " 'print_string',\n",
       " 'probability',\n",
       " 'projectivedependencyparser',\n",
       " 'prover9',\n",
       " 'punkt',\n",
       " 'pydoc',\n",
       " 'raise_unorderable_types',\n",
       " 'ranks_from_scores',\n",
       " 'ranks_from_sequence',\n",
       " 're',\n",
       " 're_show',\n",
       " 'read_grammar',\n",
       " 'read_logic',\n",
       " 'read_valuation',\n",
       " 'recall',\n",
       " 'recursivedescent',\n",
       " 'regexp',\n",
       " 'regexp_span_tokenize',\n",
       " 'regexp_tokenize',\n",
       " 'register_tag',\n",
       " 'relextract',\n",
       " 'repp',\n",
       " 'resolution',\n",
       " 'ribes',\n",
       " 'ribes_score',\n",
       " 'root_semrep',\n",
       " 'rslp',\n",
       " 'rte_classifier',\n",
       " 'rte_classify',\n",
       " 'rte_features',\n",
       " 'rtuple',\n",
       " 'scikitlearn',\n",
       " 'scores',\n",
       " 'segmentation',\n",
       " 'sem',\n",
       " 'senna',\n",
       " 'sent_tokenize',\n",
       " 'sequential',\n",
       " 'set2rel',\n",
       " 'set_proxy',\n",
       " 'sexpr',\n",
       " 'sexpr_tokenize',\n",
       " 'shiftreduce',\n",
       " 'simple',\n",
       " 'sinica_parse',\n",
       " 'skipgrams',\n",
       " 'skolemize',\n",
       " 'slice_bounds',\n",
       " 'snowball',\n",
       " 'sonority_sequencing',\n",
       " 'spearman',\n",
       " 'spearman_correlation',\n",
       " 'stack_decoder',\n",
       " 'stanford',\n",
       " 'stanford_segmenter',\n",
       " 'stem',\n",
       " 'str2tuple',\n",
       " 'string_span_tokenize',\n",
       " 'subprocess',\n",
       " 'subsumes',\n",
       " 'sum_logs',\n",
       " 'sys',\n",
       " 'tableau',\n",
       " 'tadm',\n",
       " 'tag',\n",
       " 'tagset_mapping',\n",
       " 'tagstr2tree',\n",
       " 'tbl',\n",
       " 'tee',\n",
       " 'text',\n",
       " 'textcat',\n",
       " 'texttiling',\n",
       " 'textwrap',\n",
       " 'tkinter',\n",
       " 'tnt',\n",
       " 'tokenize',\n",
       " 'tokenwrap',\n",
       " 'toktok',\n",
       " 'toolbox',\n",
       " 'total_ordering',\n",
       " 'trace',\n",
       " 'transitionparser',\n",
       " 'transitive_closure',\n",
       " 'translate',\n",
       " 'tree',\n",
       " 'tree2conllstr',\n",
       " 'tree2conlltags',\n",
       " 'treebank',\n",
       " 'treetransforms',\n",
       " 'trigrams',\n",
       " 'tuple2str',\n",
       " 'types',\n",
       " 'unify',\n",
       " 'unique_list',\n",
       " 'untag',\n",
       " 'unweighted_minimum_spanning_dict',\n",
       " 'unweighted_minimum_spanning_digraph',\n",
       " 'unweighted_minimum_spanning_tree',\n",
       " 'usage',\n",
       " 'util',\n",
       " 'version_file',\n",
       " 'viterbi',\n",
       " 'warnings',\n",
       " 'weka',\n",
       " 'windowdiff',\n",
       " 'word_tokenize',\n",
       " 'wordnet',\n",
       " 'wordpunct_tokenize',\n",
       " 'wsd']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e21c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"\"\"At eight o'clock on Thursday morning\n",
    "... Arthur didn't feel very good.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18db1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"At eight o'clock on Thursday morning\\nArthur didn't feel very good.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3051abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At',\n",
       " 'eight',\n",
       " \"o'clock\",\n",
       " 'on',\n",
       " 'Thursday',\n",
       " 'morning',\n",
       " 'Arthur',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'very',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens=nltk.word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb24dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Lenono\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag some text:'\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b1799c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('At', 'IN'),\n",
       " ('eight', 'CD'),\n",
       " (\"o'clock\", 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('morning', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7023d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Lenono\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecccd415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Lenono\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ce4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Ghostscript executable isn't found.\n",
      "See http://web.mit.edu/ghostscript/www/Install.htm\n",
      "If you're using a Mac, you can try installing\n",
      "https://docs.brew.sh/Installation then `brew install ghostscript`\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    813\u001b[0m                     [\n\u001b[1;32m--> 814\u001b[1;33m                         find_binary(\n\u001b[0m\u001b[0;32m    815\u001b[0m                             \u001b[1;34m\"gs\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    686\u001b[0m ):\n\u001b[1;32m--> 687\u001b[1;33m     return next(\n\u001b[0m\u001b[0;32m    688\u001b[0m         find_binary_iter(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m     yield from find_file_iter(\n\u001b[0m\u001b[0;32m    674\u001b[0m         \u001b[0mpath_to_bin\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"=\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m75\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n{div}\\n{msg}\\n{div}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the gs file!\nUse software specific configuration parameters or set the PATH environment variable.\n===========================================================================",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m                 )\n\u001b[0;32m    832\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_error_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'NN'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), Tree('PERSON', [('Arthur', 'NNP')]), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6cb16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jus', 'ti', 'fi', 'ca', 'tion']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import SyllableTokenizer\n",
    "from nltk import word_tokenize\n",
    "SSP = SyllableTokenizer()\n",
    "SSP.tokenize('justification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b33821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sincerely  :  sint\n",
      "electricity  :  elect\n",
      "roughly  :  rough\n",
      "ringing  :  ring\n"
     ]
    }
   ],
   "source": [
    "from nltk import LancasterStemmer\n",
    "words = ['sincerely','electricity','roughly','ringing']\n",
    "Lanc = LancasterStemmer()\n",
    "for w in words:\n",
    "    print(w, \" : \", Lanc.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da93ebe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 2 (3 4) 5)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tree import Tree\n",
    "print(Tree(1, [2, Tree(3, [4]), 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7e11e",
   "metadata": {},
   "source": [
    "# EX-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75606f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"One of the most interesting stories in the history of mathematics is the development of calculus. Calculus is a branch of mathematics that deals with the study of change and motion, and it has had a profound impact on the fields of physics, engineering, and economics.The development of calculus is usually attributed to two men: Sir Isaac Newton and Gottfried Wilhelm Leibniz. Both men independently developed the basic principles of calculus in the late 17th century, and their work laid the foundation for much of modern mathematics and science.Newton was an English mathematician and scientist who is best known for his work on the laws of motion and gravitation. He was also a pioneer in the field of optics and made important contributions to the development of calculus. Newton's work on calculus was inspired by his work on the laws of motion, which he began studying in the 1660s. He was trying to understand how objects move and change over time, and he realized that calculus was the key to understanding these processes.Leibniz was a German mathematician and philosopher who is also credited with the development of calculus. Like Newton, Leibniz was interested in understanding change and motion, and he developed a set of mathematical tools that could be used to analyze these processes. Leibniz's work on calculus was inspired by his interest in the foundations of mathematics and his desire to find a way to represent and understand complex processes in a more precise and systematic way.Despite their similar interests, Newton and Leibniz had very different approaches to calculus. Newton's approach was more intuitive and focused on the physical world, while Leibniz's approach was more abstract and focused on the mathematical principles that underlie calculus. Despite their differences, both men made important contributions to the field, and their work has had a lasting impact on mathematics and science.Today, calculus is an essential tool in many fields, including physics, engineering, economics, and computer science. It is used to model and analyze complex systems, to understand the behavior of physical phenomena, and to solve problems in a wide variety of fields. Without the contributions of Newton and Leibniz, it is likely that our understanding of the world would be significantly less advanced than it is today.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2e8ffdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the most interesting stories in the history of mathematics is the development of calculus. Calculus is a branch of mathematics that deals with the study of change and motion, and it has had a profound impact on the fields of physics, engineering, and economics.The development of calculus is usually attributed to two men: Sir Isaac Newton and Gottfried Wilhelm Leibniz. Both men independently developed the basic principles of calculus in the late 17th century, and their work laid the foundation for much of modern mathematics and science.Newton was an English mathematician and scientist who is best known for his work on the laws of motion and gravitation. He was also a pioneer in the field of optics and made important contributions to the development of calculus. Newton's work on calculus was inspired by his work on the laws of motion, which he began studying in the 1660s. He was trying to understand how objects move and change over time, and he realized that calculus was the key to understanding these processes.Leibniz was a German mathematician and philosopher who is also credited with the development of calculus. Like Newton, Leibniz was interested in understanding change and motion, and he developed a set of mathematical tools that could be used to analyze these processes. Leibniz's work on calculus was inspired by his interest in the foundations of mathematics and his desire to find a way to represent and understand complex processes in a more precise and systematic way.Despite their similar interests, Newton and Leibniz had very different approaches to calculus. Newton's approach was more intuitive and focused on the physical world, while Leibniz's approach was more abstract and focused on the mathematical principles that underlie calculus. Despite their differences, both men made important contributions to the field, and their work has had a lasting impact on mathematics and science.Today, calculus is an essential tool in many fields, including physics, engineering, economics, and computer science. It is used to model and analyze complex systems, to understand the behavior of physical phenomena, and to solve problems in a wide variety of fields. Without the contributions of Newton and Leibniz, it is likely that our understanding of the world would be significantly less advanced than it is today.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0648d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenono\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdd7d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87cf2966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'interesting',\n",
       " 'stories',\n",
       " 'in',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " 'is',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'calculus',\n",
       " '.',\n",
       " 'Calculus',\n",
       " 'is',\n",
       " 'a',\n",
       " 'branch',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " 'that',\n",
       " 'deals',\n",
       " 'with',\n",
       " 'the',\n",
       " 'study',\n",
       " 'of',\n",
       " 'change',\n",
       " 'and',\n",
       " 'motion',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'has',\n",
       " 'had',\n",
       " 'a',\n",
       " 'profound',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'the',\n",
       " 'fields',\n",
       " 'of',\n",
       " 'physics',\n",
       " ',',\n",
       " 'engineering',\n",
       " ',',\n",
       " 'and',\n",
       " 'economics.The',\n",
       " 'development',\n",
       " 'of',\n",
       " 'calculus',\n",
       " 'is',\n",
       " 'usually',\n",
       " 'attributed',\n",
       " 'to',\n",
       " 'two',\n",
       " 'men',\n",
       " ':',\n",
       " 'Sir',\n",
       " 'Isaac',\n",
       " 'Newton',\n",
       " 'and',\n",
       " 'Gottfried',\n",
       " 'Wilhelm',\n",
       " 'Leibniz',\n",
       " '.',\n",
       " 'Both',\n",
       " 'men',\n",
       " 'independently',\n",
       " 'developed',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'principles',\n",
       " 'of',\n",
       " 'calculus',\n",
       " 'in',\n",
       " 'the',\n",
       " 'late',\n",
       " '17th',\n",
       " 'century',\n",
       " ',',\n",
       " 'and',\n",
       " 'their',\n",
       " 'work',\n",
       " 'laid',\n",
       " 'the',\n",
       " 'foundation',\n",
       " 'for',\n",
       " 'much',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'mathematics',\n",
       " 'and',\n",
       " 'science.Newton',\n",
       " 'was',\n",
       " 'an',\n",
       " 'English',\n",
       " 'mathematician',\n",
       " 'and',\n",
       " 'scientist',\n",
       " 'who',\n",
       " 'is',\n",
       " 'best',\n",
       " 'known',\n",
       " 'for',\n",
       " 'his',\n",
       " 'work',\n",
       " 'on',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'motion',\n",
       " 'and',\n",
       " 'gravitation',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'also',\n",
       " 'a',\n",
       " 'pioneer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'optics',\n",
       " 'and',\n",
       " 'made',\n",
       " 'important',\n",
       " 'contributions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'calculus',\n",
       " '.',\n",
       " 'Newton',\n",
       " \"'s\",\n",
       " 'work',\n",
       " 'on',\n",
       " 'calculus',\n",
       " 'was',\n",
       " 'inspired',\n",
       " 'by',\n",
       " 'his',\n",
       " 'work',\n",
       " 'on',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'motion',\n",
       " ',',\n",
       " 'which',\n",
       " 'he',\n",
       " 'began',\n",
       " 'studying',\n",
       " 'in',\n",
       " 'the',\n",
       " '1660s',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'how',\n",
       " 'objects',\n",
       " 'move',\n",
       " 'and',\n",
       " 'change',\n",
       " 'over',\n",
       " 'time',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'realized',\n",
       " 'that',\n",
       " 'calculus',\n",
       " 'was',\n",
       " 'the',\n",
       " 'key',\n",
       " 'to',\n",
       " 'understanding',\n",
       " 'these',\n",
       " 'processes.Leibniz',\n",
       " 'was',\n",
       " 'a',\n",
       " 'German',\n",
       " 'mathematician',\n",
       " 'and',\n",
       " 'philosopher',\n",
       " 'who',\n",
       " 'is',\n",
       " 'also',\n",
       " 'credited',\n",
       " 'with',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'calculus',\n",
       " '.',\n",
       " 'Like',\n",
       " 'Newton',\n",
       " ',',\n",
       " 'Leibniz',\n",
       " 'was',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'understanding',\n",
       " 'change',\n",
       " 'and',\n",
       " 'motion',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'set',\n",
       " 'of',\n",
       " 'mathematical',\n",
       " 'tools',\n",
       " 'that',\n",
       " 'could',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'these',\n",
       " 'processes',\n",
       " '.',\n",
       " 'Leibniz',\n",
       " \"'s\",\n",
       " 'work',\n",
       " 'on',\n",
       " 'calculus',\n",
       " 'was',\n",
       " 'inspired',\n",
       " 'by',\n",
       " 'his',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'the',\n",
       " 'foundations',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " 'and',\n",
       " 'his',\n",
       " 'desire',\n",
       " 'to',\n",
       " 'find',\n",
       " 'a',\n",
       " 'way',\n",
       " 'to',\n",
       " 'represent',\n",
       " 'and',\n",
       " 'understand',\n",
       " 'complex',\n",
       " 'processes',\n",
       " 'in',\n",
       " 'a',\n",
       " 'more',\n",
       " 'precise',\n",
       " 'and',\n",
       " 'systematic',\n",
       " 'way.Despite',\n",
       " 'their',\n",
       " 'similar',\n",
       " 'interests',\n",
       " ',',\n",
       " 'Newton',\n",
       " 'and',\n",
       " 'Leibniz',\n",
       " 'had',\n",
       " 'very',\n",
       " 'different',\n",
       " 'approaches',\n",
       " 'to',\n",
       " 'calculus',\n",
       " '.',\n",
       " 'Newton',\n",
       " \"'s\",\n",
       " 'approach',\n",
       " 'was',\n",
       " 'more',\n",
       " 'intuitive',\n",
       " 'and',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'the',\n",
       " 'physical',\n",
       " 'world',\n",
       " ',',\n",
       " 'while',\n",
       " 'Leibniz',\n",
       " \"'s\",\n",
       " 'approach',\n",
       " 'was',\n",
       " 'more',\n",
       " 'abstract',\n",
       " 'and',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mathematical',\n",
       " 'principles',\n",
       " 'that',\n",
       " 'underlie',\n",
       " 'calculus',\n",
       " '.',\n",
       " 'Despite',\n",
       " 'their',\n",
       " 'differences',\n",
       " ',',\n",
       " 'both',\n",
       " 'men',\n",
       " 'made',\n",
       " 'important',\n",
       " 'contributions',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " ',',\n",
       " 'and',\n",
       " 'their',\n",
       " 'work',\n",
       " 'has',\n",
       " 'had',\n",
       " 'a',\n",
       " 'lasting',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'mathematics',\n",
       " 'and',\n",
       " 'science.Today',\n",
       " ',',\n",
       " 'calculus',\n",
       " 'is',\n",
       " 'an',\n",
       " 'essential',\n",
       " 'tool',\n",
       " 'in',\n",
       " 'many',\n",
       " 'fields',\n",
       " ',',\n",
       " 'including',\n",
       " 'physics',\n",
       " ',',\n",
       " 'engineering',\n",
       " ',',\n",
       " 'economics',\n",
       " ',',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'science',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'used',\n",
       " 'to',\n",
       " 'model',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'complex',\n",
       " 'systems',\n",
       " ',',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'the',\n",
       " 'behavior',\n",
       " 'of',\n",
       " 'physical',\n",
       " 'phenomena',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'problems',\n",
       " 'in',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'fields',\n",
       " '.',\n",
       " 'Without',\n",
       " 'the',\n",
       " 'contributions',\n",
       " 'of',\n",
       " 'Newton',\n",
       " 'and',\n",
       " 'Leibniz',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'likely',\n",
       " 'that',\n",
       " 'our',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'would',\n",
       " 'be',\n",
       " 'significantly',\n",
       " 'less',\n",
       " 'advanced',\n",
       " 'than',\n",
       " 'it',\n",
       " 'is',\n",
       " 'today',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a048554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Tokens: 412\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Tokens:\",len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "986e52bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sentences: 12\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(text)\n",
    "print(\"No. of sentences:\",len(sent_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3efefab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist= FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56039b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "#sentence without punctuations\n",
    "text1 = text.translate(str.maketrans('', '', string.punctuation))\n",
    "tokens = word_tokenize(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3186688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 162 samples and 375 outcomes>\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2323ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurance of word 'our' in the paragraph 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Occurance of word 'our' in the paragraph\",fdist['our'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985376e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 frequent words are:\n",
      " [('and', 26), ('the', 22), ('of', 20), ('calculus', 12), ('to', 12)]\n"
     ]
    }
   ],
   "source": [
    "top5 = fdist.most_common(5)\n",
    "print(\"Top 5 frequent words are:\\n\",top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0624c9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenono\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'most', 'interesting', 'stories', 'in', 'the', 'history', 'of', 'mathematics', 'is', 'the', 'development', 'of', 'calculus', 'Calculus', 'is', 'a', 'branch', 'of', 'mathematics', 'that', 'deals', 'with', 'the', 'study', 'of', 'change', 'and', 'motion', 'and', 'it', 'has', 'had', 'a', 'profound', 'impact', 'on', 'the', 'fields', 'of', 'physics', 'engineering', 'and', 'economicsThe', 'development', 'of', 'calculus', 'is', 'usually', 'attributed', 'to', 'two', 'men', 'Sir', 'Isaac', 'Newton', 'and', 'Gottfried', 'Wilhelm', 'Leibniz', 'Both', 'men', 'independently', 'developed', 'the', 'basic', 'principles', 'of', 'calculus', 'in', 'the', 'late', '17th', 'century', 'and', 'their', 'work', 'laid', 'the', 'foundation', 'for', 'much', 'of', 'modern', 'mathematics', 'and', 'scienceNewton', 'was', 'an', 'English', 'mathematician', 'and', 'scientist', 'who', 'is', 'best', 'known', 'for', 'his', 'work', 'on', 'the', 'laws', 'of', 'motion', 'and', 'gravitation', 'He', 'was', 'also', 'a', 'pioneer', 'in', 'the', 'field', 'of', 'optics', 'and', 'made', 'important', 'contributions', 'to', 'the', 'development', 'of', 'calculus', 'Newtons', 'work', 'on', 'calculus', 'was', 'inspired', 'by', 'his', 'work', 'on', 'the', 'laws', 'of', 'motion', 'which', 'he', 'began', 'studying', 'in', 'the', '1660s', 'He', 'was', 'trying', 'to', 'understand', 'how', 'objects', 'move', 'and', 'change', 'over', 'time', 'and', 'he', 'realized', 'that', 'calculus', 'was', 'the', 'key', 'to', 'understanding', 'these', 'processesLeibniz', 'was', 'a', 'German', 'mathematician', 'and', 'philosopher', 'who', 'is', 'also', 'credited', 'with', 'the', 'development', 'of', 'calculus', 'Like', 'Newton', 'Leibniz', 'was', 'interested', 'in', 'understanding', 'change', 'and', 'motion', 'and', 'he', 'developed', 'a', 'set', 'of', 'mathematical', 'tools', 'that', 'could', 'be', 'used', 'to', 'analyze', 'these', 'processes', 'Leibnizs', 'work', 'on', 'calculus', 'was', 'inspired', 'by', 'his', 'interest', 'in', 'the', 'foundations', 'of', 'mathematics', 'and', 'his', 'desire', 'to', 'find', 'a', 'way', 'to', 'represent', 'and', 'understand', 'complex', 'processes', 'in', 'a', 'more', 'precise', 'and', 'systematic', 'wayDespite', 'their', 'similar', 'interests', 'Newton', 'and', 'Leibniz', 'had', 'very', 'different', 'approaches', 'to', 'calculus', 'Newtons', 'approach', 'was', 'more', 'intuitive', 'and', 'focused', 'on', 'the', 'physical', 'world', 'while', 'Leibnizs', 'approach', 'was', 'more', 'abstract', 'and', 'focused', 'on', 'the', 'mathematical', 'principles', 'that', 'underlie', 'calculus', 'Despite', 'their', 'differences', 'both', 'men', 'made', 'important', 'contributions', 'to', 'the', 'field', 'and', 'their', 'work', 'has', 'had', 'a', 'lasting', 'impact', 'on', 'mathematics', 'and', 'scienceToday', 'calculus', 'is', 'an', 'essential', 'tool', 'in', 'many', 'fields', 'including', 'physics', 'engineering', 'economics', 'and', 'computer', 'science', 'It', 'is', 'used', 'to', 'model', 'and', 'analyze', 'complex', 'systems', 'to', 'understand', 'the', 'behavior', 'of', 'physical', 'phenomena', 'and', 'to', 'solve', 'problems', 'in', 'a', 'wide', 'variety', 'of', 'fields', 'Without', 'the', 'contributions', 'of', 'Newton', 'and', 'Leibniz', 'it', 'is', 'likely', 'that', 'our', 'understanding', 'of', 'the', 'world', 'would', 'be', 'significantly', 'less', 'advanced', 'than', 'it', 'is', 'today']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Lexical Dispersion Plot'}, xlabel='Word Offset'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yellowbrick.text import DispersionPlot\n",
    "target_words = ['and', 'the', 'of', 'calculus', 'to']\n",
    "print(tokens)\n",
    "visualizer = DispersionPlot(target_words)\n",
    "visualizer.fit([tokens])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86cc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
