{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "C3XSKLUbJ0AL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQAkH65lJz8y",
        "outputId": "c96c08c2-35b9-439e-d68a-9aebc5918047"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-nAr0JkJz6k",
        "outputId": "7fe8d4b1-e334-46b2-bfcf-49397dd276e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF2YF6o3Jz4L",
        "outputId": "6f60bb99-20ec-4bcb-c3a0-9fc0977b6f09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I love my mom's cooking\""
      ],
      "metadata": {
        "id": "guAnmyvtJz1i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = nltk.tokenize.word_tokenize(text)"
      ],
      "metadata": {
        "id": "0iWJJtnJJzy7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_tagged = nltk.pos_tag(words)"
      ],
      "metadata": {
        "id": "m_8ssL-sJzwW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = \"NP: {<JJ><NN>}\""
      ],
      "metadata": {
        "id": "sL8uMwyyKFoV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = nltk.RegexpParser(grammar)\n",
        "tree = parser.parse(words_tagged)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO_XWMHmKGOb",
        "outputId": "371e390b-2c5d-494d-eb65-3c26e176106d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S I/PRP love/VBP my/PRP$ mom/NN 's/POS cooking/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, collections\n",
        "from IPython.display import display, Markdown, Latex\n"
      ],
      "metadata": {
        "id": "9MlDV8zYvIVW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(vocab):\n",
        "    \"\"\"Compute frequencies of adjacent pairs of symbols.\"\"\"\n",
        "    pairs = collections.defaultdict(int)\n",
        "    for word, freq in vocab.items():\n",
        "        symbols = word.split()\n",
        "        for i in range(len(symbols)-1):\n",
        "            pairs[symbols[i],symbols[i+1]] += freq\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "JnxnIoMKvcVr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_vocab(pair, v_in):\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "    for word in v_in:\n",
        "        w_out = p.sub(''.join(pair), word)\n",
        "        v_out[w_out] = v_in[word]\n",
        "    return v_out"
      ],
      "metadata": {
        "id": "9XDxKysfvcLN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w e s t </w>': 6, 'w i d e s t </w>': 3}"
      ],
      "metadata": {
        "id": "c0_R8OQFvlfk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bpe_codes = {}\n",
        "bpe_codes_reverse = {}"
      ],
      "metadata": {
        "id": "X8CpDidyvrwA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_merges = 10\n",
        "\n",
        "for i in range(num_merges):\n",
        "    display(Markdown(\"### Iteration {}\".format(i + 1)))\n",
        "    pairs = get_stats(train_data)\n",
        "    best = max(pairs, key=pairs.get)\n",
        "    train_data = merge_vocab(best, train_data)\n",
        "    \n",
        "    bpe_codes[best] = i\n",
        "    bpe_codes_reverse[best[0] + best[1]] = best\n",
        "    \n",
        "    print(\"new merge: {}\".format(best))\n",
        "    print(\"train data: {}\".format(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "m2VFO8G6vJbl",
        "outputId": "d838ab87-764a-4e74-a11d-c7f9421a0cec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 1"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('e', 's')\n",
            "train data: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w es t </w>': 6, 'w i d es t </w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 2"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('es', 't')\n",
            "train data: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est </w>': 6, 'w i d est </w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 3"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('est', '</w>')\n",
            "train data: {'l o w </w>': 5, 'l o w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 4"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('l', 'o')\n",
            "train data: {'lo w </w>': 5, 'lo w e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 5"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('lo', 'w')\n",
            "train data: {'low </w>': 5, 'low e r </w>': 2, 'n e w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 6"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('n', 'e')\n",
            "train data: {'low </w>': 5, 'low e r </w>': 2, 'ne w est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 7"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('ne', 'w')\n",
            "train data: {'low </w>': 5, 'low e r </w>': 2, 'new est</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 8"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('new', 'est</w>')\n",
            "train data: {'low </w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 9"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('low', '</w>')\n",
            "train data: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'w i d est</w>': 3}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Iteration 10"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new merge: ('w', 'i')\n",
            "train data: {'low</w>': 5, 'low e r </w>': 2, 'newest</w>': 6, 'wi d est</w>': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as a tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs\n"
      ],
      "metadata": {
        "id": "6RaYUzhMv0HY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def encode(orig):\n",
        "    \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\"\"\"\n",
        "\n",
        "    word = tuple(orig) + ('</w>',)\n",
        "    display(Markdown(\"__word split into characters:__ <tt>{}</tt>\".format(word)))\n",
        "\n",
        "    pairs = get_pairs(word)    \n",
        "\n",
        "    if not pairs:\n",
        "        return orig\n",
        "\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        iteration += 1\n",
        "        display(Markdown(\"__Iteration {}:__\".format(iteration)))\n",
        "        \n",
        "        print(\"bigrams in the word: {}\".format(pairs))\n",
        "        bigram = min(pairs, key = lambda pair: bpe_codes.get(pair, float('inf')))\n",
        "        print(\"candidate for merging: {}\".format(bigram))\n",
        "        if bigram not in bpe_codes:\n",
        "            display(Markdown(\"__Candidate not in BPE merges, algorithm stops.__\"))\n",
        "            break\n",
        "        first, second = bigram\n",
        "        new_word = []\n",
        "        i = 0\n",
        "        while i < len(word):\n",
        "            try:\n",
        "                j = word.index(first, i)\n",
        "                new_word.extend(word[i:j])\n",
        "                i = j\n",
        "            except:\n",
        "                new_word.extend(word[i:])\n",
        "                break\n",
        "\n",
        "            if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                new_word.append(first+second)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_word.append(word[i])\n",
        "                i += 1\n",
        "        new_word = tuple(new_word)\n",
        "        word = new_word\n",
        "        print(\"word after merging: {}\".format(word))\n",
        "        if len(word) == 1:\n",
        "            break\n",
        "        else:\n",
        "            pairs = get_pairs(word)\n",
        "\n",
        "    # don't print end-of-word symbols\n",
        "    if word[-1] == '</w>':\n",
        "        word = word[:-1]\n",
        "    elif word[-1].endswith('</w>'):\n",
        "        word = word[:-1] + (word[-1].replace('</w>',''),)\n",
        "   \n",
        "    return word"
      ],
      "metadata": {
        "id": "c9BdUurDvNi7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"lowest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "KUZqxOn2vUAq",
        "outputId": "8108b84c-8430-454a-f1e8-ec9c8416c78e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__word split into characters:__ <tt>('l', 'o', 'w', 'e', 's', 't', '</w>')</tt>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 1:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('t', '</w>'), ('w', 'e'), ('l', 'o'), ('e', 's'), ('s', 't'), ('o', 'w')}\n",
            "candidate for merging: ('e', 's')\n",
            "word after merging: ('l', 'o', 'w', 'es', 't', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 2:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('t', '</w>'), ('l', 'o'), ('w', 'es'), ('o', 'w'), ('es', 't')}\n",
            "candidate for merging: ('es', 't')\n",
            "word after merging: ('l', 'o', 'w', 'est', '</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 3:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('l', 'o'), ('est', '</w>'), ('w', 'est'), ('o', 'w')}\n",
            "candidate for merging: ('est', '</w>')\n",
            "word after merging: ('l', 'o', 'w', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 4:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('l', 'o'), ('w', 'est</w>'), ('o', 'w')}\n",
            "candidate for merging: ('l', 'o')\n",
            "word after merging: ('lo', 'w', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 5:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('w', 'est</w>'), ('lo', 'w')}\n",
            "candidate for merging: ('lo', 'w')\n",
            "word after merging: ('low', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Iteration 6:__"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bigrams in the word: {('low', 'est</w>')}\n",
            "candidate for merging: ('low', 'est</w>')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "__Candidate not in BPE merges, algorithm stops.__"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('low', 'est')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}